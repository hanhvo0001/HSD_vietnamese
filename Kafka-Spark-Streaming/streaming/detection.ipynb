{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "039c7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emot --upgrade\n",
    "# !pip install regex\n",
    "# !pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d379edb5-59bc-4c50-9759-c3009b03e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kafka-python\n",
    "# !pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd54abc3-8d5e-40d3-bdc3-b9fa453bb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6924bf69-ce8a-4dda-80bd-8671031f7a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8bc7f8f-9300-43d0-83ca-f49e23b8516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec6e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from confluent_kafka import Consumer, KafkaError, Producer\n",
    "import socket\n",
    "import logging\n",
    "from preprocessing import preprocessing\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import torch\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\n",
    "from transformers import BertTokenizer, BertForSequenceClassification,AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7321e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create consumer\n",
    "def create_consumer(topic, group_id):\n",
    "    try:\n",
    "        consumer = Consumer({\"bootstrap.servers\": \"localhost:9092\",\n",
    "                             \"group.id\": group_id,\n",
    "                             \"client.id\": socket.gethostname(),\n",
    "                             \"isolation.level\": \"read_committed\",\n",
    "                             \"default.topic.config\": {\"auto.offset.reset\": \"latest\", # Only consume new messages\n",
    "                                                      \"enable.auto.commit\": False}\n",
    "                             })\n",
    "\n",
    "        consumer.subscribe([topic])\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Couldn't create the consumer\")\n",
    "        consumer = None\n",
    "\n",
    "    return consumer\n",
    "# Create a producer\n",
    "def create_producer():\n",
    "    try:\n",
    "        producer = Producer({\"bootstrap.servers\": \"localhost:9092\",\n",
    "                             \"client.id\": socket.gethostname(),\n",
    "                             \"enable.idempotence\": True,  # EOS processing\n",
    "                             \"compression.type\": \"lz4\",\n",
    "                             \"batch.size\": 64000,\n",
    "                             \"linger.ms\": 10,\n",
    "                             \"acks\": \"all\",  # Wait for the leader and all ISR to send response back\n",
    "                             \"retries\": 5,\n",
    "                             \"delivery.timeout.ms\": 1000})  # Total time to make retries\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Couldn't create the producer\")\n",
    "        producer = None\n",
    "    return producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36381c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # create consumer\n",
    "    consumer = create_consumer(topic=\"hsd\",group_id=\"hsd\")\n",
    "    # create producer\n",
    "    producer = create_producer()\n",
    "    \n",
    "    # load DNN model\n",
    "#     model_path = os.path.abspath('../model/Text_CNN_model_PhoW2V.h5')\n",
    "#     model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    \n",
    "    # load tokenizer\n",
    "#     tknz_path = os.path.abspath('../model/tokenizer.pickle')\n",
    "#     with open(tknz_path,\"rb\") as f:\n",
    "#         tokenizer = pickle.load(f)\n",
    "\n",
    "    # Load Phobert_model\n",
    "    ## pbert_path = os.path.abspath('../transformer_model/phobert-v3/')\n",
    "    pretrained_model = AutoModelForSequenceClassification.from_pretrained(\"E:/Download/phobert-v3/\", local_files_only=True)\n",
    "    model = Trainer(model=pretrained_model)\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\",use_fast=False)\n",
    "    \n",
    "    class BuildDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "    \n",
    "    # Consumer\n",
    "    try:\n",
    "        while True:\n",
    "            message = consumer.poll(0.5)\n",
    "            if message is None:\n",
    "                continue\n",
    "            elif not message.error():\n",
    "                print('Received')\n",
    "                record = json.loads(message.value().decode('utf-8'))\n",
    "                date = record[\"datetime\"]\n",
    "                comment = record[\"comment\"]\n",
    "                author = record[\"author\"]\n",
    "                processed_comment = preprocessing(comment)\n",
    "                \n",
    "                # dnn\n",
    "#                 seq_comment = tokenizer.texts_to_sequences([processed_comment])\n",
    "#                 ds_comment = sequence.pad_sequences(seq_comment,maxlen=80)\n",
    "#                 pred = model.predict(ds_comment)\n",
    "#                 hsd_dt = pred.argmax(-1)\n",
    "                \n",
    "                # bert\n",
    "                seq_comment = bert_tokenizer([comment],truncation=True, padding=True, max_length=100)\n",
    "                ds_comment = BuildDataset(seq_comment, [0])\n",
    "                \n",
    "                pred = model.predict(ds_comment)\n",
    "                hsd_dt = np.argmax(pred.predictions,axis=-1)\n",
    "                print(f\"Date: {date}, Comment: {processed_comment}, HSD_detect: {hsd_dt}, Author: {author}\")\n",
    "                \n",
    "                # Send message to detected topic\n",
    "                dict_ = {'author':author,'date':date,'raw_comment':comment,'clean_comment':processed_comment,'label':int(hsd_dt[0])}\n",
    "                sending_record = json.dumps(dict_).encode(\"utf-8\")\n",
    "                producer.produce(topic=\"detected\",value=sending_record)\n",
    "                producer.flush(30)\n",
    "                print('Detection sent!')\n",
    "                \n",
    "            elif message.error().code() == KafkaError._PARTITION_EOF:\n",
    "                print('End of partition reached {0}/{1}'\n",
    "                      .format(message.topic(), message.partition()))\n",
    "            else:\n",
    "                print('Error occured: {0}'.format(message.error().str()))\n",
    "    except KeyboardInterrupt:\n",
    "        print('Stop consume!')\n",
    "        pass\n",
    "\n",
    "    finally:\n",
    "        consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da4544bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='29' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 04:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2021-10-08T22:34:59Z, Comment: nhạc hay nhảy lại đẹp nữa, HSD_detect: [0], Author: AT- Official\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-10-08T10:41:21Z, Comment: hay vay noi, HSD_detect: [0], Author: anh ba sánh\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-10-07T09:21:00Z, Comment: ổng ghép nhạc, HSD_detect: [0], Author: anh ba sánh\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-10-01T11:23:24Z, Comment: múa hài_vậy, HSD_detect: [0], Author: Quê GL\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-10-01T02:18:23Z, Comment: nhìn nhóc trẻ trâu, HSD_detect: [1], Author: MY BÒ SỮA\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-09-21T17:28:22Z, Comment: anh phong nhảy vui vãi, HSD_detect: [0], Author: Trí Lê minh\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-09-21T11:29:35Z, Comment: yêu lắm ️, HSD_detect: [0], Author: Mai Trần\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-09-18T07:28:14Z, Comment: hay thật_sự, HSD_detect: [0], Author: tôi là ếch xanh\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-09-13T13:46:49Z, Comment: anh_em nào còn nghe không kết nhất đoạn behind the_scene, HSD_detect: [0], Author: Dustin\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-09-10T07:24:18Z, Comment: me facina ️ phong max aishiteru, HSD_detect: [0], Author: Ilda Flores\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-09-03T06:00:07Z, Comment: bà ơi bà sca báo, HSD_detect: [0], Author: Hung Tran\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-08-30T02:50:02Z, Comment: em có mắt_kính, HSD_detect: [0], Author: đệ VinhMc\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-08-28T09:59:25Z, Comment: , HSD_detect: [0], Author: đệ VinhMc\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-08-23T08:57:34Z, Comment: tua đoạn múa quạt đi, HSD_detect: [0], Author: Son Tran\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-08-11T12:56:27Z, Comment: ai còn nghe không nhỉ, HSD_detect: [0], Author: KIếm tiền online\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-08-10T08:28:55Z, Comment: hay quá anh ơi, HSD_detect: [0], Author: Huyen Sam Phan\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-28T12:27:06Z, Comment: chúa_tể remix ông hoàng giật giật, HSD_detect: [0], Author: Sang Hà Ngọc\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-26T08:15:19Z, Comment: tui bảo_đảm với các bạn loa kẹo kéo vô phòng lo mà lắc, HSD_detect: [0], Author: Mị Vinahouse\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-20T16:49:15Z, Comment: hai, HSD_detect: [0], Author: Ho Hai\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-17T02:15:18Z, Comment: cái thằng đội nón bảo_hiểm biết nhảy không, HSD_detect: [0], Author: Kiệm Mai văn\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-15T02:57:18Z, Comment: ơ_kìa pay lắc giữa đồng hoang ha_ha, HSD_detect: [0], Author: Thien Lee\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-09T06:35:22Z, Comment: mình rất thích phong_cách của bạn chúc bạn sức_khỏe nhiều may_mắn cống_hiến thêm nhiều nữa những thú_vị cho khán_giả nhé mãi yêu ️, HSD_detect: [0], Author: Hùng Bùng Nhùng\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-03T04:02:10Z, Comment: thằng cu trong bụng quẩy theo nhạc luôn, HSD_detect: [0], Author: Thu Hoang\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-07-02T03:19:03Z, Comment: phong max lam nhac hay quá chiu khong noi luon, HSD_detect: [0], Author: Tan Tran\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-06-17T01:08:11Z, Comment: hay quá, HSD_detect: [0], Author: Cuong Ngo\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-06-13T15:55:32Z, Comment: hay quá đã đăng_kí kênh, HSD_detect: [0], Author: Ty Le Van\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-06-02T15:27:28Z, Comment: no bi khung, HSD_detect: [0], Author: em bé\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-05-30T15:42:33Z, Comment: sao lại thấy quần_áo toàn đen thôi vậy ông, HSD_detect: [0], Author: Ho Tan\n",
      "Detection sent!\n",
      "Received\n",
      "Date: 2021-05-30T09:51:14Z, Comment: hay, HSD_detect: [0], Author: Thuyen Trieu\n",
      "Detection sent!\n",
      "Stop consume!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
